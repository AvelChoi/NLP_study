## 03) 어간추출과 표제어 추출
> 자연어 처리에서 전처리, 더 정확히는 정규화의 지향점은 언제나 갖고 있는 코퍼스로부터 복잡성을 줄이는 일

궁극적으로 코퍼스의 복잡성을 줄이고, 일반화의 가능성을 높이는 것이다.

### 1. 표제어 추출(Lemmatization)
> 표제어(Lemma)는 한글로는 '표제어' 또는 '기본 사전형 단어' 정도의 의미

교재의 예시에 따르면 am, are, is의 기본형은 모두 be다. 따라서 표제어는 뿌리 단어를 찾아가는 것이라고 할 수 있다.

표제어 추출을 하는 가장 섬세한 방법으로 "단어의 형태학적 파싱"을 먼저 진행하는 법이 있다고 한다. 형태소의 정의는 다음과 같다.
> 의미를 가진 가장 작은 단위

한편, 형태학은 "형태소로부터 단어를 만들어가는 학문을 뜻한다." 이건 무슨 연관이 있는지 아직은 모르겠다.
아무튼 영어와 달리, 띄어쓰기로 의미가 잘 구분되지 않는 한국어 자연어처리에서는 형태소 분석이 중요하다. 

> 어간(stem): 단어의 의미를 담고 있는 단어의 핵심 부분
> 
> 접사(affix): 단어에 추가적인 의미를 주는 부분

그러니까 어간은 단어의 핵심으로, 의미를 가장 많이 담고 있다. 반면 접사는 단어에 추가적인 의미를 준다.
그렇다면 "형태학적 파싱"은 이 두 가지 구성 요소를 분리하는 작업이 될 것이다.

예시로 cats라는 단어에 대해 형태학적 파싱을 수행한다면, 어간은 cat이 되고 접사는 s가 된다.
반면 fox는 독립적인 형태소이기 때문에 더 이상 분리할 수 없다. 

#### NLTK 패키지의 일부인 WordNetLemmatizer 실습

실습 결과
> 표제어 추출 전:  ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']

>표제어 추출 후: ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']

이렇듯 접사가 있는 단어들은 어간과 분리가 이루어진 것을 확인할 수 있으나... has를 ha로 바꿔버리는 오류를 범하고 있다.
교재에서는 이것의 원인을 "표제어 추출기(lemmatizer)가 본래 단어의 품사 정보를 알아야만 정확한 결과를 얻을 수 있기 때문"으로 짚고 있다.

당연히 NLTK 패키지는 이런 문제점을 보완할 수 있는 기능들을 마련해놓고 있다.
입력으로 단어가 동사 품사라는 사실을 알려줄 수 있다는 것이 그 예시다.

> 즉, dies와 watched, has가 문장에서 동사로 쓰였다는 것을 알려준다면 표제어 추출기는 품사의 정보를 보존하면서 정확한 Lemma를 출력하게 됩니다.

#### WordNetLemmatizer의 단어의 품사를 입력
> print(lemmatizer.lemmatize('dies', 'v')) 
> 
>print(lemmatizer.lemmatize('watched', 'v'))
> 
>print(lemmatizer.lemmatize('has', 'v'))

> die
> 
> watch
> 
> have

이렇듯 "표제어 추출은 문맥을 고려하며 수행했을 때의 결과는 해당 단어의 품사 정보를 보존"한다.
그러나 여전히 문제점이 남아있다. 어간 추출을 수행했을 때의 결과에는 품사 정보가 보존되지 않는다.
따라서, 어간 추출을 한 결과는 사전에 존재하지 않는 단어일 경우가 많다.