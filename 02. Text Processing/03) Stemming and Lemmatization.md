## 03) 어간추출과 표제어 추출

> 자연어 처리에서 전처리, 더 정확히는 정규화의 지향점은 언제나 갖고 있는 코퍼스로부터 복잡성을 줄이는 일

궁극적으로 코퍼스의 복잡성을 줄이고, 일반화의 가능성을 높이는 것이다.

### 1. 표제어 추출(Lemmatization)

> 표제어(Lemma)는 한글로는 '표제어' 또는 '기본 사전형 단어' 정도의 의미

교재의 예시에 따르면 am, are, is의 기본형은 모두 be다. 따라서 표제어는 뿌리 단어를 찾아가는 것이라고 할 수 있다.

표제어 추출을 하는 가장 섬세한 방법으로 "단어의 형태학적 파싱"을 먼저 진행하는 법이 있다고 한다. 형태소의 정의는 다음과 같다.
> 의미를 가진 가장 작은 단위

한편, 형태학은 "형태소로부터 단어를 만들어가는 학문을 뜻한다." 이건 무슨 연관이 있는지 아직은 모르겠다.
아무튼 영어와 달리, 띄어쓰기로 의미가 잘 구분되지 않는 한국어 자연어처리에서는 형태소 분석이 중요하다.

> 어간(stem): 단어의 의미를 담고 있는 단어의 핵심 부분
>
> 접사(affix): 단어에 추가적인 의미를 주는 부분

그러니까 어간은 단어의 핵심으로, 의미를 가장 많이 담고 있다. 반면 접사는 단어에 추가적인 의미를 준다.
그렇다면 "형태학적 파싱"은 이 두 가지 구성 요소를 분리하는 작업이 될 것이다.

예시로 cats라는 단어에 대해 형태학적 파싱을 수행한다면, 어간은 cat이 되고 접사는 s가 된다.
반면 fox는 독립적인 형태소이기 때문에 더 이상 분리할 수 없다.

#### NLTK 패키지의 일부인 WordNetLemmatizer 실습

실습 결과
> 표제어 추출
> 전:  ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']

> 표제어 추출
> 후: ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']

이렇듯 접사가 있는 단어들은 어간과 분리가 이루어진 것을 확인할 수 있으나... has를 ha로 바꿔버리는 오류를 범하고 있다.
교재에서는 이것의 원인을 "표제어 추출기(lemmatizer)가 본래 단어의 품사 정보를 알아야만 정확한 결과를 얻을 수 있기 때문"으로 짚고 있다.

당연히 NLTK 패키지는 이런 문제점을 보완할 수 있는 기능들을 마련해놓고 있다.
입력으로 단어가 동사 품사라는 사실을 알려줄 수 있다는 것이 그 예시다.

> 즉, dies와 watched, has가 문장에서 동사로 쓰였다는 것을 알려준다면 표제어 추출기는 품사의 정보를 보존하면서 정확한 Lemma를 출력하게 됩니다.

#### WordNetLemmatizer의 단어의 품사를 입력

> print(lemmatizer.lemmatize('dies', 'v'))
>
>print(lemmatizer.lemmatize('watched', 'v'))
>
>print(lemmatizer.lemmatize('has', 'v'))

> die
>
> watch
>
> have

이렇듯 "표제어 추출은 문맥을 고려하며 수행했을 때의 결과는 해당 단어의 품사 정보를 보존"한다.
그러나 여전히 문제점이 남아있다. 어간 추출을 수행했을 때의 결과에는 품사 정보가 보존되지 않는다.
따라서, 어간 추출을 한 결과는 사전에 존재하지 않는 단어일 경우가 많다.

### 2. 어간 추출(Stemming)

어간 추출이란, 말 그대로 "어간을 추출하는 작업"을 뜻한다.
섬세하지 않기 때문에 어간 추출 후 나오는 단어는 사전에 존재하지 않는 단어일 수도 있다고 한다.

#### 포터 알고리즘 실습

> This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights
> and soundings--with the single exception of the red crosses and the written notes.

> 어간 추출 전 ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', "'s", 'chest', ',', 'but', 'an', '
> accurate', 'copy', ...

> 어간 추출 후 ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', "'s", 'chest', ',', 'but', 'an', '
> accur', 'copi', ...

This를 thi로, copy를 copi로 변환한 것이 눈에 띈다. 이렇듯 포터 알고리즘은 사전에 없는 단어를 추출하는 경우가 있다.

그러니까, 한국어를 쓰는 나에게는 다소 신기한(?) 방법이긴 한데, 나에게 친숙한 단어인 Spcialized를 예시로 들어보도록 하자.
교재에서는 "formalize"를 예시로 들었다. 포터 알고리즘에 따르면 Specialized는 Special로 변환된다고 한다.
즉, 이렇듯 최대한 단어의 원형으로 변환하려는 시도를 엿볼 수 있다.

그렇다면 여기서 들 수 있는 의문은 다음과 같다.
"아니, 사전에 없는 괴상한 단어를 만들어낼 수도 있다는데, 왜 어간 추출을 사용하는거지?"

그 답은 속도에 있다. "어간 추출 속도는 표제어 추출보다 일반적으로 빠"르다고 한다.
추출 결과물을 보면 알겠지만, 영어에서는 괜찮은 선택이 될 수 있다는 것이다.

NLTK에서는 랭커스터 스태머 알고리즘 역시 지원한다. 실습 파일에서 해당 결과를 비교해본다.

> Porter stemmer: ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']

> Lancaster stemmer: ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']

추출된 예시 중 do와 doing의 차이만 보더라도 확연하게 다른 알고리즘임이 느껴진다.
따라서 "사용하고자 하는 코퍼스에 스테머를 적용해보고 어떤 스테머가 해당 코퍼스에 적합한지 판단한 후에 사용"해야 한다고 명시하고 있다.

### 3. 한국어에서의 어간 추출

한국어는 5언 9품사의 구조를 가지고 있다. 용언에 해당되는 동사와 형용사는 어간(stem)과 어미(ending)으로 구성되어 있다.
교재에서 앞으로 용언이라고 언급한다면, 이는 동사와 형용사를 모두 포함하고 있다.

#### (1) 활용(conjugation)

활용? 우리가 흔히 아는 "잘 활용하다"의 그 한자어와 동일하다. 다만 여기서는 아래의 뜻으로 사용한다.

> 용언의 어간(stem)이 어미(ending)를 가지는 일

> 용언의 어간이나 서술격 조사에 변하는 말이 붙어 문장의 성격을 바꿈. 또는 그런 일.
> 국어에서는 동사, 형용사, 서술격 조사의 **어간에 여러 가지 어미가 붙는 형태**를 이르는데, 이로써 시제ㆍ서법 따위를 나타낸다.
>
> 출처: [표준국어대사전, 활용](https://ko.dict.naver.com/#/entry/koko/6bac60df9b43405ea3a579f5e1600611)

이 활용은, 한국어 뿐만 아니라 인도유럽어에서도 주로 볼 수 있다고 한다. 물론 여기서는 한국어 기준이긴 하다.

한국어에서 다시 한번 어간과 어미를 정의하면 다음과 같다.
> 어간(stem) : 용언(동사, 형용사)을 활용할 때, 원칙적으로 모양이 변하지 않는 부분. 활용에서 어미에 선행하는 부분.
> 때론 어간의 모양도 바뀔 수 있음(예: 긋다, 긋고, 그어서, 그어라).
>
> 어미(ending): 용언의 어간 뒤에 붙어서 활용하면서 변하는 부분이며, 여러 문법적 기능을 수행

즉, 어간 뒤에 어미가 어떻게 붙느냐?가 한국어에서는 상당히 중요한 문제가 된다.
그래서 어간이 어미를 취할 때, 어간이 일정하게 유지되느냐(규칙 활용) 혹은 어간이나 어미의 모습이 변하냐(불규칙 활용)가 중요하다.

#### (2) 규칙 활용
규칙 활용의 예시로 "잡다"를 제시하고 있다. 그 외에 무엇이 있을까?

#### (3) 불규칙 활용
우스갯소리로 한글은 쉬워도, 한국어는 어렵다는 말이 있다. 그 말에 부합하듯 불규칙 활용은 무수히 많아보인다.

> 듣/들-, 돕/도우-, 곱/고우-, 잇/이-, 올/올-, 노랗/노라-

위 사례에서는 어간이 바뀐다.

> 오르+ 아/어→올라, 하+아/어→하여, 이르+아/어→이르러, 푸르+아/어→푸르러

위 경우에서는 특수한 어미를 취한다.

그렇다면 영어와 같은 잘라내는 식의 어간 추출을 한국어에서는 정상적으로 작동하지 않을 가능성이 높고, "좀 더 복잡한 규칙을 필요로"한다.
